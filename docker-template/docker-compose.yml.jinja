name: smart-eye

# *******************************************************************
# * Author: 2024 Luigi Pizzolito (@https://github.com/Luigi-Pizzolito)
# *******************************************************************

{# TODO: add internal stream network, ?external network? #}

# Docker Compose file for SmartEye system
# defines all the Docker containers for each module/service
# as well as virtual networks, ports, configuration,
# cross-dependencies, storage volumes, etc

# ! AUTO-GENERATED BY setup.sh DO NOT EDIT
#  Instead, edit the environment configuration file: config.env
#  If you really need to edit this, make sure to edit the template
#  at docker-template/docker-compose.yml.jinja

# Define virtual networks
networks:
  kafka-net:
    driver: bridge

# Define persistent storage volumes
volumes:
  kafka_data:

# Define services and their properties
services:
  # Kafka
  # Apache Kafka + KRaft Manager
  # Handles asynchronous publisher/subscriber message channels in real-time
  # and provides disk store (DB) of all historical messages
  zookeeper:
    image: 'wurstmeister/zookeeper'
    networks:
      - kafka-net
    ports:
      - 2181:2181
  #  volumes:
   #   - zookerper_data:/bitnami/zookeeper
  kafka:
    image: 'wurstmeister/kafka'
    networks:
      - kafka-net
    environment:
    #  - KAFKA_CFG_NODE_ID=0
    #  - KAFKA_CFG_PROCESS_ROLES=controller,broker
    #  - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
    #  - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    #  - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
    #  - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    #  - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://192.168.1.103:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_LOG_SEGMENT_DELETE_DELAY_MS: 100
      KAFKA_LOG_CLEANER_DELETE_RETENTION_MS: 100
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 1000
      KAFKA_OFFSETS_RETENTION_CHECK_INTERVAL_MS: 1000
      KAFKA_LOG_RETENTION_HOURS: 0
      KAFKA_LOG_RETENTION_MINUTES: 0
      KAFKA_LOG_RETENTION_MS: 1000
      KAFKA_OFFSET_RETENTION_HOURS: 0
      KAFKA_OFFSET_RETENTION_MINUTES: 0
      KAFKA_OFFSET_RETENTION_MS: 1000
      KAFKA_LOG_FLUSH_INTERVAL_MS: 500
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 100
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    # persistent kafka storage, may also be directory mapped
    # volumes:
    #   - kafka_data:/bitnami/kafka
    # expose to localhost for testing
    ports:
      - 29092:29092
      - 9092:9092
    links:
      - zookeeper
    hostname: kafka
    depends_on:
      - zookeeper
    
  kafka-ui:
    image: provectuslabs/kafka-ui
    networks:
      - kafka-net
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
      KAFKA_CLUSTERS_0_NAME: localhost-SmartEye
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 192.168.1.104:29092
      KAFKA_CLUSTERS_1_NAME: docker-SmartEye
      KAFKA_CLUSTERS_1_BOOTSTRAPSERVERS: kafka:29092
    ports:
      - 8092:8080
    depends_on:
      - kafka

  # Video Buffer
  # ESP32CAM -> Kafka
  # Requests video streams from cameras and outputs to Kafka topics
  # Create one instance for each camera
  {%- for camera in env.CAMERAS.split(',') %}
  videobuffer-{{ camera }}:
    build:
      context: ./VideoBuffer
      dockerfile: ../dockerfiles/VideoBuffer.Dockerfile
    environment:
      - CAMERA={{ camera }}
      - TYPE={{ env[camera.upper() + '_TYPE'] }}
      {%- if env[camera.upper() + '_TYPE'] == 'espcam'  %}
      - IP={{ env[camera.upper() + '_IP'] }}
      {%- endif %}
    {%- if env[camera.upper() + '_TYPE'] == 'usbcam' %}
    devices:
      - {{ env[camera.upper() + '_DEVICE'] + ':' + env[camera.upper() + '_DEVICE'] }}
    {%- endif %}
    networks:
      - kafka-net
    depends_on:
      - kafka
    restart: unless-stopped
  {%- endfor %}

  # MJPEG Streamer
  # Kafka -> HTTP MJPEG Streaming server -> MJPEG live-streams
  # Creates HTTP MJPEG streams from Kafka, for Web UI and AI processors
  # Single instance handles all streams, multi-client
  # Be sure to set framestreams to the proper filters
  # to select which Kafka topics to process as streams
  # default: topics containing "stream"
  mjpegstreamer:
    build:
      context: ./MJPEGStreamer
      dockerfile: ../dockerfiles/MJPEGStreamer.Dockerfile
    networks:
      - kafka-net
    ports:
      - 8095:8095
      {# - 6060:6060 #} #? for profiling
    depends_on:
      - kafka
    restart: unless-stopped

  # Web Interface HTTP Server
  # Serves Web UI files to clients
  uiwebserver:
    image: nginx:latest
    ports: 
      - 8094:80
    volumes:
      - ./WebInterface:/usr/share/nginx/html
    
  {# TODO: AI Processors #}
  {%- for i in range(env.CAMERAS.split(',') | length) %}
  {%- set camera = env.CAMERAS.split(',')[i] -%}

  # Python AI Video Processing
  # Kafka Camera Streams -> Python AI -> Kafka AI Streams + Data
  # for face, pose and gesture recognition
  ai-process-kafka-{{ camera }}:
    build:
      context: ./AIProcess-Kafka
      dockerfile: ../dockerfiles/AIProcess.Dockerfile
    networks:
      - kafka-net
    depends_on:
      - kafka
      - mjpegstreamer
    volumes:
      - ./AIProcess-Data:/app/VideoProcess/Data
    environment:
      - KAFKA_SERVERS=kafka:9092
      - MJPEG_SERVER=mjpegstreamer:8095
      - IN_TOPIC={{ camera }}-stream
      - OUT_TOPIC_FACE={{ camera }}-faces-stream
      - DATA_TOPIC_FACE=data
      - OUT_TOPIC_POSE={{ camera }}-pose-stream
      - DATA_TOPIC_POSE=data
      - OUT_TOPIC_GESTURE={{ camera }}-gesture-stream
      - DATA_TOPIC_GESTURE=data
    restart: unless-stopped
  
  # WebSocket API for face register
  # accepts websocket message and image from local webcam to register new face
  # -> then we must restart the AI processes manually
  ai-process-kafka-sockapi-{{ camera }}:
    build:
      context: ./AIProcess-Kafka
      dockerfile: ../dockerfiles/AIProcess-API.Dockerfile
    networks:
      - kafka-net
    ports: 
      - {{ 8100 + i }}:8100
    depends_on:
      - kafka
      - mjpegstreamer
    volumes:
      - ./AIProcess-Data:/app/VideoProcess/Data
    restart: unless-stopped
  {%- endfor %}

  # API Data Server
  # Reads Kafka Data channel output from AI and keeps a cache
  # which WebUI can access as JSON via HTTP XHR request
  ai-process-kafka-dataserver:
    build:
      context: ./AIProcess-Kafka
      dockerfile: ../dockerfiles/AIProcess-Data.Dockerfile
    networks:
      - kafka-net
    ports:
      - 8200:8200
    depends_on:
      - kafka
    environment:
      - KAFKA_SERVERS=kafka:9092
      - DATA_TOPIC=data
      - DATA_PORT=8200

  {# TODO: MQTT Server #}
  {# TODO: Kafka<->MQTT Bridge #}

  {# TODO: Re-organise this file #}